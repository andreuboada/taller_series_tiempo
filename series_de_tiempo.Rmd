---
title: ""
output:
  html_document:
    keep_md: true
    css: estilos/modest.css
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = T, message = F, comment = NA, fig.align = "center")
```


<style>
  .espacio {
     margin-bottom: 1cm;
  }
</style>

# Series de tiempo 游늴游늳

> "It is far better to foresee even without certainty than not to foresee at all." --- Henri Poincare


# Prediciendo los pron칩sticos

La estad칤stica es una ciencia muy joven. El progreso en el an치lisis de datos y en particular en las
series de tiempo siempre ha dependido en gran medida de cu치ndo, d칩nde y c칩mo estaban 
disponibles los datos y en qu칠 cantidad.

En la 칠poca Victoriana un cient칤fico llamado Robert FitzRoy fue nombrado jefe de un nuevo departamento
del gobierno brit치nico para registrar y publicar datos relacionados con el clima para los marineros.
FitRoy hab칤a trabajado como capit치n del HMS Beagle durante el viaje que llev칩 a Charles Darwin
alrededor del mundo. Este viaje fue instrumental en proporcionar evidencia a Darwin para la teor칤a 
de la evoluci칩n por selecci칩n natural.

Desde el renacimiento, los cient칤ficos comenzaron a recopilar datos relacionados con el clima con 
la ayuda de instrumentos reci칠n inventados, como el bar칩metro, para medir el estado atmosf칠rico. Esto
con el objetivo de emplearlos para la pesca, la agricultura, o la ganader칤a.

Para _predecir_ el clima se analizaba la aparici칩n de nubes o bien el comportamiento de los animales,
por ejemplo, el toro en el campo de un granjero, una rana en un frasco, o una golondrina en un arbusto
para ver, por ejemplo, si se aproximaba una tormenta.

<div style="text-align: center;">**Predicci칩n del clima usando ranas**</div>
<center><img src="img/frog.jpg" width="400px" /></center>
<p class="espacio">
</p>

Se modernizaron los bar칩metros y estos instrumentos los utilizaron para registrar series de tiempo a
intervalos diarios o incluso por hora. Los datos se guardaban en diarios privados y libros de
registro locales de la ciudad.

<center><img src="img/fitzroy_barometer.jpg" width="150px" /></center>
<p class="espacio">
</p>

Un problema grande para FitzRoy era que se hund칤an los barcos. Entre 1866 y 1860 se hundieron
7402 barcos y se perdieron 7201 vidas. FitzRoy cre칤a que si se pod칤a prever esto muchas vidas
se hubieran salvado. Cuando se hundi칩 el Royal Charter en 1859 le dieron la facultad de comenzar 
a emitir advertencias de tormenta.

FitzRoy acu침칩 el t칠rmino *pron칩stico*. En ese momento, fue criticado por la calidad de sus
pron칩sticos, pero ahora se considera que estaba adelantado a su 칠poca. 
Estableci칩 la costumbre de imprimir pron칩sticos del tiempo en el peri칩dico _The Times_.

<center><img src="img/metofficenew.jpg" width="350px" /></center>
<p class="espacio">
</p>

Leer m치s en: https://www.bbc.com/news/magazine-32483678

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(reshape2)
library(gridExtra)
knitr::opts_chunk$set(comment=NA, fig.align="center")
```


<style>
  .espacio {
     margin-bottom: 1cm;
  }
</style>

## El despegue de las series de tiempo

Los desarrollos te칩ricos en el an치lisis de series de tiempo comenzaron con procesos estoc치sticos.
La primera aplicaci칩n real de los modelos que se usan actualmente a los datos comenz칩 en el
trabajo de G. U Yule y J. Walker en las d칠cadas de 1920 y 1930, pero el problema es que no se
lograba encontrar una soluci칩n de m치xima verosimilitud para una clase de modelos m치s generales.

Tom칩 hasta 1970 antes de que esto se lograra. En ese momento, sali칩 el cl치sico libro "An치lisis de
series temporales" de G. E. P. Box y G. M. Jenkins, que contiene el procedimiento de modelado completo
para series individuales: especificaci칩n, estimaci칩n, diagn칩stico y pron칩stico.

Hoy en d칤a, los denominados modelos Box-Jenkins son quiz치s los m치s utilizados y muchas t칠cnicas
utilizadas para la predicci칩n y el ajuste estacional se remontan a estos modelos.

<center><img src="img/boxjenkins.jpg" width="200px" /></center>
<p class="espacio">
</p>

### Modelos aditivos

El enfoque de series de tiempo como modelo aditivo es de la siguiente manera. 
Supongamos que tenemos una serie de tiempo en la cual observamos "ciclos".
A esto normalmente se le llama "descomposici칩n tendencia-ciclo".


Por lo tanto, pensamos que una serie de tiempo comprende tres componentes: un componente 
de ciclo de tendencia, un componente estacional y un componente restante (que contiene
cualquier otra cosa en la serie de tiempo).

Si suponemos una descomposici칩n aditiva, entonces podemos escribir:

$$
y_t = S_t + T_t + R_t
$$
donde $y_t$ son los datos, $S_t$ es la compnente estacional, $T_t$ es la componente de
tendencia-ciclo, y $R_t$ es la componente de residuo, todos en un periodo $t$.

Alternativamente, una descomposici칩n multiplicativa se escribir칤a como

$$
y_t = S_t \times T_t \times R_t.
$$
La descomposici칩n aditiva es la m치s apropiada si la magnitud de las fluctuaciones estacionales,
o la variaci칩n alrededor del ciclo de tendencia, no var칤a con el nivel de la serie temporal.
Cuando la variaci칩n en el patr칩n estacional, o la variaci칩n alrededor del ciclo de tendencia,
parece ser proporcional al nivel de la serie de tiempo, entonces una descomposici칩n
multiplicativa es m치s apropiada. Las descomposiciones multiplicativas son comunes con las
series de tiempo econ칩micas.

Una alternativa al uso de una descomposici칩n multiplicativa es transformar primero los datos
hasta que la variaci칩n en la serie parece ser estable en el tiempo, luego usar una
descomposici칩n aditiva. Cuando se ha utilizado una transformaci칩n logar칤tmica, esto es
equivalente a usar una descomposici칩n multiplicativa porque

$$
y_t=S_t\times T_t \times R_t \quad \mbox{es equivalente a }\quad \mbox{log}(y_t) = \mbox{log}(S_t)+ \mbox{log}(T_t) + \mbox{log}(R_t).
$$


### 쮺칩mo hacemos an치lisis de series de tiempo?

Podemos usar el suavizamiento loess para entender y describir el comportamiento
de series de tiempo, en las cuales intentamos entender la dependencia de una
serie de mediciones indexadas por el tiempo. T칤picamente es necesario utilizar 
distintas *componentes* para describir exitosamente una serie de tiempo, y para
esto usamos distintos tipos de suavizamientos. Veremos que distintas
*componentes* var칤an en distintas escalas de tiempo (unas muy lentas, cono la
tendencia, otras m치s rapidamente, como variaci칩n quincenal, etc.).

En el siguiente ejemplo consideramos la ventas semanales de un producto a lo 
largo de 5 a침os. Veamos que existe una tendencia a largo plazo (crecimientos
anuales) y tambi칠n que existen patrones de variaci칩n estacionales.

```{r, fig.width=5.5, fig.height = 3}
ventas <- read_csv("datos/ventas_semanal.csv")
ggplot(ventas, aes(x = period, y = sales.kg)) + geom_line(size = 0.3)
```

Intentaremos usar suavizamiento para capturar los distintos tipos de variaci칩n
que observamos en la serie. En primer lugar, si suavizamos poco (por ejemplo
$\alpha = 0.1$), vemos que capturamos en parte la tendencia y en parte la 
variaci칩n estacional.

```{r, fig.width=5.5, fig.height = 3}
ggplot(ventas, aes(x = period, y = log(sales.kg))) +
  geom_line(size = 0.3) +
  geom_smooth(method = "loess", span = 0.1, se = FALSE, size = 1, 
    color = "red")
```

Es mejor comenzar capturando la tendencia, y poco de la componente estacional:

```{r, fig.width=5.5, fig.height = 3}
ggplot(ventas, aes(x = period, y = log(sales.kg))) +
  geom_line(size = 0.3) +
  geom_smooth(method = "loess", span = 0.3, se = FALSE, size = 1, 
    color = "red")

ajuste.trend.1 <- loess(log(sales.kg) ~ period, ventas, span = 0.3)
ventas$trend.1 <- ajuste.trend.1$fitted
ventas$res.trend.1 <- ajuste.trend.1$residuals
```

Ahora calculamos los residuales de este ajuste e intentamos describirlos 
mediante un suavizamiento m치s fino. Verificamos que hemos estimado la mayor
parte de la tendencia, e intentamos capturar la variaci칩n estacional de los 
residuales.

```{r, fig.width=5.5, fig.height = 3}
ggplot(ventas, aes(x = period, y = res.trend.1)) +
  geom_line(size = 0.3) +
  geom_smooth(method = "loess", span = 0.15, se = FALSE, size = 1, color = "red")

ajuste.est1.1 <- loess(res.trend.1 ~ period, ventas, span = 0.15, degree = 1)
ventas$est1.1 <- ajuste.est1.1$fitted
ventas$res.est1.1 <- ajuste.est1.1$residuals
```

Y graficamos los residuales obtenidos despu칠s de ajustar el componente 
estacional para estudiar la componente de mayor frecuencia.

```{r, fig.width=5.5, fig.height = 3}
ggplot(ventas, aes(x = period, y = res.est1.1)) +
  geom_line(size = 0.3) +
  geom_smooth(method = "loess", span = 0.06, se = FALSE, size = 1, 
    color = "red")

ajuste.est2.1 <- loess(res.est1.1 ~ period, ventas, span = 0.06, degree = 1)
ventas$est2.1 <- ajuste.est2.1$fitted
ventas$res.est2.1 <- ajuste.est2.1$residuals
```

Ahora que tenemos nuestra primera estimaci칩n de cada una de las componentes, 
podemos regresar a hacer una mejor estimaci칩n de la tendencia. La ventaja de 
volver es que ahora podemos suavizar m치s sin que en nuestra muestra compita
tanto la variaci칩n estacional. Por tanto podemos suavizar menos:

```{r, fig.width=5.5, fig.height = 3}
ventas$sales.sin.est.1 <- log(ventas$sales.kg) - ajuste.est1.1$fitted - 
  ajuste.est2.1$fitted

ggplot(ventas, aes(x = period, y = sales.sin.est.1)) +
  geom_line(size = 0.3) +
  geom_smooth(method = "loess", span = 0.08, se = FALSE, size = 1, color = "red")

ajuste.trend.2 <- loess(sales.sin.est.1 ~ period, ventas, span = 0.08, degree = 1)
ventas$trend.2 <- ajuste.trend.2$fitted
ventas$res.trend.2 <- log(ventas$sales.kg) - ventas$trend.2
```

Y ahora nos concentramos en la componente anual.

```{r, fig.width=5.5, fig.height = 3}
ventas$sales.sin.est.2 <- log(ventas$sales.kg) - ajuste.trend.2$fitted -
  ajuste.est2.1$fitted
ggplot(ventas, aes(x = period, y = sales.sin.est.2)) +
  geom_line(size = 0.3) +
  geom_smooth(method = "loess", span = 0.2, se = FALSE, size = 1, color = "red")

ajuste.est1.2 <- loess(sales.sin.est.2 ~ period, ventas, span = 0.15, degree = 1)
ventas$est1.2 <- ajuste.est1.2$fitted
ventas$res.est1.2 <- ajuste.est1.2$residuals
```

Finalmente volvemos a ajustar la componente de frecuencia m치s alta:

```{r, fig.width=5.5, fig.height = 3}
ventas$sales.sin.est.3 <- log(ventas$sales.kg) - ajuste.trend.2$fitted -
  ajuste.est1.2$fitted

ggplot(ventas, aes(x = period, y = sales.sin.est.3)) +
  geom_line(size = 0.3) +
  geom_smooth(method = "loess", span = 0.06, se = FALSE, size = 1, 
    color = "red")

ajuste.est2.2 <- loess(sales.sin.est.3 ~ period, ventas, span = 0.06, degree = 1)
ventas$est2.2 <- ajuste.est2.2$fitted
ventas$res.est2.2 <- ajuste.est2.2$residuals
```

Verificamos nuestra descomposici칩n y visualizamos el ajuste:

```{r, fig.width = 5.5, fig.height = 7}
ventas$log.sales <- log(ventas$sales.kg)
ventas.2 <- dplyr::select(ventas, period, trend.2, est1.2, est2.2, res.est2.2, 
  log.sales)
#max(abs(apply(ventas.2[, 2:4], 1, sum) - ventas.2$log.sales))

ventas.2.m <- gather(ventas.2, componente, valor, -period)

ventas.2.m.c <- ventas.2.m %>%
  group_by(componente) %>%
  mutate(
    valor.c = valor - mean(valor)
  )

ggplot(ventas.2.m.c, aes(x = period, y = valor.c)) +
  geom_vline(xintercept = c(0, 52 - 1, 52 * 2 - 1, 52 * 3 - 1, 52 * 4 - 1), color = "gray") +
  geom_line(size = 0.3) +
  facet_wrap(~ componente, ncol = 1)
```

Y vemos que es razonable describir los residuales con una distribuci칩n normal 
(con desviaci칩n est치ndar alrededor de 8% sobre el valor ajustado):

```{r, fig.width=3.6, fig.height=3.6}
#sd(ventas$res.est2.2)
ventas.ord <- arrange(ventas, res.est2.2)
ventas.ord$q.normal <- qnorm((1:nrow(ventas) - 0.5) / nrow(ventas))
ggplot(ventas.ord, aes(x = q.normal, y = res.est2.2)) +
  geom_point(size = 1.2) +
  geom_smooth(method = "lm")
```

Hay dos cosas que nos falta explicar, en primer lugar, las ca칤das alrededor de
principios/finales de cada a침o (que son de hasta -0.2), y segundo que esta 
gr치fica parece oscilar demasiado. La estructura que a칰n no hemos explicado se
debe a que las semanas que caen en quincena tienden a tener compras m치s 
grandes que las que est치n justo antes de quincena o fin de mes.

Por el momento detendremos el an치lisis aqu칤 y explicamos un proceso iterativo
para proceder en nuestro an치lisis exploratorio:

<p class="espacio">
</p>
<div class="title_box">
<p class="espacio">
</p>
&nbsp;&nbsp;&nbsp;**Iterando ajuste de loess.** 

&nbsp;&nbsp;Cuando queremos ajustar con tres componentes: tendencia, estacionalidad y residuales, podemos seguir el siguiente proceso,

1. Ajustar la primera componente a los datos (tendencia).

2. Ajustar la segunda componente a los residuales del paso anterior 
(estacionalidad).

3. Restar de los datos originales la segunda componente ajustada 
(estacionalidad).

4. Ajustar a los residuales del paso anterior una nueva componente (tendencia).

5. Restar a los datos originales la componente ajustada en el paso anterior.

6. Ajustar a los residuales del paso anterior una nueva componente 
(estacionalidad).

7. Checar ajuste y si es necesario iterar de 3 a 6 con las nuevas componentes.


<p class="espacio">
</p>
</div>
<p class="espacio">
</p>
<p class="espacio">
</p>


La idea es que cada componente compite para explicar los datos (cada una gana
m치s al bajar el par치metro $\alpha$). El conflicto es que si suavizamos mucho
cada componente (por ejemplo la tendencia), entonces parte de la variaci칩n 
que deber칤a ir en ella queda en los residuales, y se intenta ajustar 
posteriormente por una componente distinta (estacionalidad). Sin embargo, si 
suavizamos poco, entonces parte de la variaci칩n de la segunda componente es
explicada por el ajuste de la primera. Entonces, la soluci칩n es ir poco a poco
adjudicando variaci칩n a cada componente. En nuestro ejemplo de arriba, podemos
comenzar suavizando de menos el primer ajsute de la tendencia, luego ajustar
estacionalidad, restar a los datos originales esta estacionalidad, y ajustar a
estos datos una componente m치s suave de tendencia. Es posible suavizar m치s la
tendencia justamente porque ya hemos eliminado una buena parte de la
estacionalidad.

Ahora, si vemos c칩mo se comportan los residuales seg칰n el d칤a donde comienza la
semana, vemos el patr칩n que explicamos antes:

```{r, fig.width = 4, fig.height=3.8}
dat.tot <- read_csv(file = "datos/cereal_tot.csv")
ventas.day <- inner_join(ventas,dplyr::select(dat.tot, period, day),by='period')
```

```{r, message=FALSE, warning=FALSE, comment=NA, fig.width = 4, fig.height=3.8}
ggplot(ventas.day, aes(x = day, y = res.est2.2)) +
  geom_point() +
  ylab("residual") +
  geom_smooth(method = "loess", span = 0.06, se = FALSE, size = 1, color = "red")
```


Podemos hacer un ajuste loess con estos residuales:

```{r, fig.width=5.5, fig.height = 3}
ajuste.quincenas <- loess(res.est2.2 ~ day, data = ventas.day)
ventas$quincena <- ajuste.quincenas$fitted
ventas$res.final <- ajuste.quincenas$residuals
sd(ventas$quincena)
sd(ventas$res.final)

ggplot(ventas, aes(x = period, y = res.final)) +
  geom_line(size = 0.3) +
  geom_point(size = 1.2)
```

```{r, fig.width = 5.5, fig.height = 7}
ventas.2 <- dplyr::select(ventas, period, trend.2, est1.2, est2.2, quincena, 
  res.final, log.sales)
max(abs(apply(ventas.2[, 2:4], 1, sum) - ventas.2$log.sales))

ventas.2.m <- gather(ventas.2, componente, valor, -period)

ventas.2.m.c <- ventas.2.m %>%
  group_by(componente) %>%
  mutate(
    valor.c = valor - mean(valor)
  )

ggplot(ventas.2.m.c, aes(x = period, y = valor.c)) +
  geom_vline(xintercept = c(0, 52 - 1, 52 * 2 - 1, 52 * 3 - 1, 52 * 4 - 1), color = "gray") +
  geom_line(size = 0.3) +
  facet_wrap(~ componente, ncol = 1)
```


```{r fig.height=8, fig.width=12, message=TRUE}
library(nullabor)
ventas.res.2 <- dplyr::select(ventas, period, res.final)
ventas.null.2 <- lineup(null_dist(var = 'res.final', dist = 'normal', 
  params = list(mean = 0, sd = 0.0636)), n = 20, ventas.res.2)

ggplot(ventas.null.2, aes(x = period, y = res.final)) +
  facet_wrap(~ .sample, ncol = 4) + 
  geom_line(size = 0.3) +
  geom_vline(xintercept = c(0, 52 - 1, 52 * 2 - 1, 52 * 3 - 1, 52 * 4 - 1), 
             color = "gray") + 
  geom_point(size = 1.2) 
```


### Otro ejemplo de la descomposici칩n cl치sica

Veamos un ejemplo con los datos `co2` del paquete `ggplot2`. Estos datos muestran las concentraciones atmosf칠ricas de CO2, que se expresan en partes por mill칩n (ppm)
y se informan en la escala preliminar de fracci칩n molar manom칠trica SIO de 1997.

```{r fig.height=7, fig.width=11, message=FALSE, warning=FALSE}
library(forecast)
co2 %>% 
  decompose(type = "multiplicative") %>% 
  autoplot + 
  xlab("A침o") +
  ggtitle("Descomposici칩n multiplicativa cl치sica de 
          concentraci칩n atmosf칠rica de CO2 (1959-1997)")
```

Utilizaremos los datos `elecequip` del paquete `fpp` para el resto de este taller. Estos datos muestran el n칰mero de nuevos pedidos de equipos el칠ctricos (computadoras, productos electr칩nicos
y 칩pticos) en 16 pa칤ses de Europa. Los datos ya han sido ajustados por el n칰mero de d칤as h치biles y normalizados, por lo que un valor de 100 corresponde a 2005.

```{r fig.height=7, fig.width=11, message=FALSE, warning=FALSE}
elecequip <- read_csv("datos/elecequip.csv") 
elecequip <- ts(elecequip$x, start=c(1996, 1), end=c(2012, 3), frequency=12)

elecequip %>% decompose(type="multiplicative") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition
    of electrical equipment index")
```

La valores de residuaels por debajo de 1 en 2009 sugieren que hay una cierta "fuga" del componente 
de tendencia (ciclo) en el componente de residuales. La estimaci칩n de la tendencia ha suavizado 
en exceso la ca칤da de los datos, y los valores restantes correspondientes se han visto afectados
por la pobre estimaci칩n de la tendencia.

### Comentarios sobre la descomposici칩n cl치sica

Si bien la descomposici칩n cl치sica todav칤a se usa ampliamente, no se recomienda, ya que ahora 
hay varios m칠todos mucho mejores. Algunos de los problemas con la descomposici칩n cl치sica se
resumen a continuaci칩n.

* La estimaci칩n de la tendencia no est치 disponible para las primeras y 칰ltimas 
observaciones. Por ejemplo, si $m = 12$, no hay una estimaci칩n del ciclo de tendencia para 
las primeras seis o las 칰ltimas seis observaciones. En consecuencia, tampoco existe una 
estimaci칩n del componente restante para los mismos per칤odos de tiempo.

* La estimaci칩n de tendencias (ciclos) tiende a suavizar los aumentos y ca칤das r치pidas en los
datos (como se ve en el ejemplo anterior).

* Los m칠todos de descomposici칩n cl치sicos suponen que el componente estacional se repite de a침o
en a침o. Para muchas series, esta es una suposici칩n razonable, pero para algunas series m치s largas
no lo es. Por ejemplo, los patrones de demanda de electricidad han cambiado con el tiempo a medida
que el aire acondicionado se ha generalizado. Espec칤ficamente, en muchos lugares, el patr칩n de uso
estacional de hace varias d칠cadas tuvo su demanda m치xima en invierno (debido a la calefacci칩n),
mientras que el patr칩n estacional actual tiene su demanda m치xima en verano (debido al aire
acondicionado). Los m칠todos de descomposici칩n cl치sicos no pueden capturar estos cambios estacionales
a lo largo del tiempo.

* Ocasionalmente, los valores de las series de tiempo en un peque침o n칰mero de per칤odos pueden ser
particularmente inusuales. Por ejemplo, el tr치fico mensual de pasajeros a칠reos puede verse afectado
por una disputa industrial, lo que hace que el tr치fico durante la disputa sea diferente al habitual. 
El m칠todo cl치sico no es robusto para este tipo de valores inusuales.

## Seasonal Trend Loess (STL) 

Lowess estacional es un m칠todo de descomposici칩n basado en m칤nimos cuadrados ponderados localmente. 
En general, estos m칠todos son una alternativa a los modelos autorregresivos / de media m칩vil (ARMA).
Los m칠todos de descomposici칩n son un enfoque preferible cuando la tendencia y los componentes
estacionales dominan la serie. Esto se usa generalmente para _desestacionalizar_ las series.

Veamos ahora c칩mo se ven los datos estacionales de cada mes en la serie:

```{r}
fit <- decompose(elecequip, type="additive") #additive decomposition
g1 <- autoplot(elecequip)
g1 + geom_line(data = seasadj(fit), color = "red")
```

Observamos que aumenta en Marzo, Junio, Septiembre a Diciembre y disminuye en Agosto:

```{r}
ggfortify::ggfreqplot(elecequip, freq=12)
```


```{r}
fits <- stl(elecequip, s.window=7)
monthplot(fits, choice = "seasonal")
```

Ahora graficamos la serie ajustada por la estacionalidad. Observamos que ya no se tiene esa
variaci칩n estacional porque esta puede ser explicada por separado:

```{r}
eeadj <- seasadj(stl(elecequip, s.window="periodic"))
autoplot(eeadj) 
```

Vemos un nuevo ajuste. La distribuci칩n de los residuales es menos dram치tica que en la motivaci칩n anterior.

```{r}
fitloess <- stl(elecequip, t.window=15, s.window="periodic", robust=TRUE)
autoplot(fitloess)#grafica tanto con tendencia y ajuste de estacionalidad
```

## Modelos autorregresivos (AR)

Un modelo autorregresivo utiliza instancias anteriores de cada medici칩n como predictor en 
un modelo lineal para futuras instancias.

$$
y_t = \beta_0 + \sum_{i=1}^p{\beta_i y_{t-i}} + \varepsilon_t
$$

donde los par치metros a ajustar son las $\beta_i$'s. Como de costumbre, se supone que los 
t칠rminos de error siguen una distribuci칩n normal con media 0 (por ejemplo, 
$\varepsilon\sim N(0, \sigma)$. Podemos ajustar el modelo usando regresi칩n OLS, 
pero aqu칤 usaremos una funci칩n especial de R.

El modelo autorregresivo $\mbox{AR}(p)$ usa $p$ t칠rminos rezagados (lags).

```{r}
ar.mod <- ar(eeadj, order.max = 5)
ar.mod
```

```{r}
ar.hats <- predict(ar.mod, n.ahead=24)
plot(eeadj, xlim=c(1996, 2014))
lines(ar.hats$pred, col="blue")
lines(ar.hats$pred + ar.hats$se, col="red")
lines(ar.hats$pred - ar.hats$se, col="red")
```

## Modelos de promedios m칩viles (MA)

Los modelos de promedios m칩viles son similares, pero usan los t칠rminos de error en 
lugar de las observaciones anteriores. Es decir, aqu칤 las mediciones se basan en los
errores rezagados, en lugar de las observaciones rezagadas.

El modelo de promedios m칩viles de orden $q$ se denota por $\mbox{MA}(q)$:

$$
y_t = \mu + \sum_{j=1}^q{\theta_i\varepsilon_{t-i}} + \varepsilon_t
$$
donde los par치metros que se deben ajustar son las $\theta_i$'s.


Ajuste sencillo de medias m칩viles:

```{r}
ma.mod <- ma(eeadj, order = 12)
plot(eeadj, ylab="New orders index", col="gray",
 main="Electrical equipment manufacturing (Euro area)")
lines(ma.mod, col="red") #moving average for m=12
```


## Algunos conceptos

### Estacionariedad

Una serie temporal estacionaria es aquella cuyas propiedades no dependen del momento en 
que se observa la serie, es decir, ${y_t}$ es estacionaria si para toda $s$ la distribuci칩n de 
$$
(y_t, y_{y+1},\ldots,y_{t+s})
$$
no depende de $t$ (siempre es la misma). Existen muchas definiciones de estacionariedad. (Ver [9])

Por lo tanto, las series temporales con tendencias o con estacionalidad no son estacionarias: 
la tendencia y la estacionalidad afectar치n el valor de la serie temporal en tiempos diferentes. 
Por otro lado, una serie de ruido blanco es estacionaria: no importa cuando se observe, deber칤a 
verse muy similar en cualquier momento.

Algunos casos pueden ser confusos: una serie temporal con comportamiento c칤clico (pero sin tendencia
ni estacionalidad) es estacionaria. Esto se debe a que los ciclos no son de una longitud fija, por lo
que antes de observar la serie no podemos estar seguros de d칩nde estar치n los picos y los m칤nimos 
de los ciclos.

En general, una serie temporal estacionaria no tendr치 patrones predecibles a largo plazo. Las 
gr치ficos mostrar치n que la serie es aproximadamente horizontal (aunque es posible un comportamiento
c칤clico), con una variaci칩n constante.

Veamos las siguientes gr치ficas [3]:

(a) precio de las acciones de Google durante 200 d칤as consecutivos; 
(b) Cambio diario en el precio de las acciones de Google durante 200 d칤as consecutivos; 
(c) N칰mero anual de huelgas en los Estados Unidos; 
(d) Ventas mensuales de nuevas casas unifamiliares vendidas en los Estados 
Unidos; 
(e) Precio anual de una docena de huevos en los Estados Unidos (d칩lares constantes); 
(f) Total mensual de cerdos sacrificados en Victoria, Australia; 
(g) Total anual de linces atrapados en el distrito del r칤o McKenzie del noroeste de Canad치; 
(h) Producci칩n mensual de cerveza australiana;
(i) Producci칩n mensual de electricidad en Australia.

<center><img src="img/stationary-1.png" width="800px" /></center>
<p class="espacio">
</p>


*쮺u치l de 칠stas crees que es estacionaria?*

La estacionalidad obvia descarta las series (d), (h) e (i). Las tendencias y los niveles 
cambiantes descartan las series (a), (c), (e), (f) e (i). La varianza creciente tambi칠n 
descarta (i). Eso deja solo (b) y (g) como series estacionarias.


### 쮺u치l de las siguientes series es estacionaria?

Las siguientes gr치ficas muestran con qu칠 frecuencia se ha visto un art칤culo a lo largo del tiempo 
para las p치ginas de los 3 jugadores de football: Peyton Manning, Patrick Mahomes, y Jared Goff.

```{r fig.height=4, fig.width=12, message=FALSE, warning=FALSE}
library(wikipediatrend)

page_views_pm1 <- wp_trend("Peyton_Manning", from = "2016-01-01", to = "2020-03-18")
page_views_pm2 <- wp_trend("Patrick_Mahomes", from = "2016-01-01", to = "2020-03-18")
page_views_jg <- wp_trend("Jared_Goff", from = "2016-01-01", to = "2020-03-18")

gpm1 <- ggplot(page_views_pm1, aes(x=date, y=log(views))) + 
  geom_point(size=1.5, colour="steelblue") + 
  geom_smooth(method="loess", colour="#2dcccd", fill="#2dcccd", alpha=0.4, span = 0.1) +
  scale_y_continuous( breaks=seq(5e6, 50e6, 5e6) , 
  label= paste(seq(5,50,5),"M") ) + xlab("Fecha") + ylab("N칰mero de visitas (log)") +
  ggtitle("Payton Manning") +
  theme_bw()

gpm2 <- ggplot(page_views_pm2, aes(x=date, y=log(views))) + 
  geom_point(size=1.5, colour="steelblue") + 
  geom_smooth(method="loess", colour="#2dcccd", fill="#2dcccd", alpha=0.4, span = 0.1) +
  scale_y_continuous( breaks=seq(5e6, 50e6, 5e6) , 
  label= paste(seq(5,50,5),"M") ) + xlab("Fecha") + ylab("N칰mero de visitas (log)") +
  ggtitle("Patrick Mahomes") +
  theme_bw()

gjg <- ggplot(page_views_jg, aes(x=date, y=log(views))) + 
  geom_point(size=1.5, colour="steelblue") + 
  geom_smooth(method="loess", colour="#2dcccd", fill="#2dcccd", alpha=0.4, span = 0.1) +
  scale_y_continuous( breaks=seq(5e6, 50e6, 5e6) , 
  label= paste(seq(5,50,5),"M") ) + xlab("Fecha") + ylab("N칰mero de visitas (log)") +
  ggtitle("Jared Goff") +
  theme_bw()

grid.arrange(gpm1, gpm2, gjg, ncol = 3)
```

쮸 qu칠 jugadores corresponden la(s) series estacionarias?

a) Payton y Jared
b) Patrick y Jared
c) Solamente la de Jared
d) Solamente la de Payton

### Diferenciaci칩n

Veamos de nuevo las gr치ficas (a) y (b) de las acciones de Google arriba. Vemos que el 
precio de las acciones de Google no era estacionario en (a), pero los cambios diarios eran
estacionarios en (b). Esto muestra una forma de hacer que una serie de tiempo no estacionaria 
sea estacionaria: calculando las diferencias entre observaciones consecutivas. 
A esto se le conoce como _diferenciaci칩n_.

Calcular logaritmo puede ayudar a estabilizar la varianza de una serie, mientras que
la diferenciaci칩n puede ayudar a estabilizar la media, al eliminar los cambios en el nivel de
la serie y, por lo tanto, eliminar (o reducir) la tendencia y la estacionalidad.

La gr치fica de _autocorrelaciones_ (*ACF*) tambi칠n es 칰til para identificar series de tiempo no
estacionarias. Para una serie de tiempo estacionaria, ka ACF caer치 a cero relativamente r치pido,
mientras que cuando los datos son no estacionarios disminuye, la ACF disminuye lentamente. 

<center><img src="img/acfstationary-1.png" width="600px" /></center>
<p class="espacio">
</p>

### Diferenciaci쑕

A veces es necesario tomar una diferencia estacional y una primera diferencia para obtener datos
estacionarios. Ahora vemos un ejemplo en el cual los datos se transforman primero usando logaritmo
(segundo panel), luego se calculan las diferencias estacionales (tercer panel). 
Los datos todav칤a parecen algo no estacionarios, por lo que se calculan nuevamente diferencias.

```{r fig.height=10, message=FALSE, warning=FALSE}
usmelec <- read_rds("datos/usmelec.rds")
cbind("Billion kWh" = usmelec,
      "Logs" = log(usmelec),
      "Seasonally\n differenced logs" =
        diff(log(usmelec),12),
      "Doubly\n differenced logs" =
        diff(diff(log(usmelec),12),1)) %>%
  autoplot(facets=TRUE) +
    xlab("Year") + ylab("") +
    ggtitle("Monthly US net electricity generation")
```


## ARIMA

Si combinamos la diferenciaci칩n con autorregresi칩n y un modelo de promedio m칩vil, 
obtenemos un modelo ARIMA no estacional. ARIMA es un acr칩nimo de 
_AutoRegressive Integrated Moving Average_ (en este contexto, "integraci칩n" es lo 
contrario de la diferenciaci칩n). El modelo completo se puede escribir como

$$
y^\prime_t = c + \sum_{i=1}^p{\beta_i y_{t-i}} + \sum_{j=1}^q{\theta_i\varepsilon_{t-i}} + \varepsilon_t
$$

donde $y^\prime_t$ es la serie diferenciada (puede haber sido diferenciada m치s de una vez). 
Los "predictores" en el lado derecho incluyen ambos valores rezagados de $y_t$ y errores rezagados. 
A esto lo llamamos $\mbox{ARIMA}(p,d,q)$ modelo, donde

* $p$ = orden de la parte autorregresiva;
* $d$ = grado de primera diferencia involucrada;
* $q$ = orden de la parte media m칩vil.

### Ejemplo: Gasto de consumo de EE. UU.

La serie muestra cambios porcentuales trimestrales en el gasto de consumo de los Estados Unidos. 
Aunque es una serie trimestral, no parece haber un patr칩n estacional, por lo que ajustaremos un 
modelo ARIMA no estacional.

```{r}
uschange <- read_rds("datos/uschange.rds")
autoplot(uschange[,"Consumption"]) +
  xlab("Year") + ylab("Quarterly percentage change")
```

El siguiente c칩digo R se utiliz칩 para seleccionar un modelo autom치ticamente.

```{r}
fit <- auto.arima(uschange[,"Consumption"], seasonal=FALSE)
```


Esto es un modelo $ARIMA(1,0,3)$ :
$$
y_t = c + 0.589 y_{t-1} -0.353\varepsilon_{t-1} + 0.0846\varepsilon_{t-2}+0.174\varepsilon_{t-3} + \varepsilon_{t-3}
$$


```{r}
fit %>% forecast(h=10) %>% autoplot(include=80)
```

# Referencias 

[1] Aileen Nielsen (2019). Practical Time Series Analysis. O'Reilly.

[2] Box, G. E., & Jenkins, G. M. (1970). Time series analysis: Forecasting and control Holden-Day. San Francisco, 498.

[3] Hyndman, R. J., & Athanasopoulos, G. (2018). Forecasting: principles and practice. OTexts.

[4] Peter Meissner (2019). wikipediatrend: Public Subject Attention via Wikipedia Page View Statistics. R
  package version 2.1.4.

[5] Owen S. Vallis, Jordan Hochenbaum and Arun Kejariwal (2014). AnomalyDetection: Anomaly Detection Using Seasonal Hybrid Extreme Studentized Deviate Test. R package version 1.0.1.

[6] Wickham, H., & Grolemund, G. (2016). R for data science.

[7] Guerrero Guzm치n, V. M. (2003). An치lisis estad칤stico de series de tiempo econ칩micas (No. 04; Q280, G8 2003.).

[8] Cleveland, W. S. (1993) Visualizing Data. New Jersey: Summit Press.

[9] Myers, Donald E. "To be or not to be... stationary? That is the question." Mathematical Geology 21.3 (1989): 347-362.
